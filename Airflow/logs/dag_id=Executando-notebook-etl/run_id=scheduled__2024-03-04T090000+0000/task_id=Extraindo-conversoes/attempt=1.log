[2024-03-05T21:04:00.142-0300] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [queued]>
[2024-03-05T21:04:00.149-0300] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [queued]>
[2024-03-05T21:04:00.150-0300] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-03-05T21:04:00.167-0300] {taskinstance.py:2214} INFO - Executing <Task(DatabricksRunNowOperator): Extraindo-conversoes> on 2024-03-04 09:00:00+00:00
[2024-03-05T21:04:00.169-0300] {standard_task_runner.py:60} INFO - Started process 28701 to run task
[2024-03-05T21:04:00.171-0300] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'Executando-notebook-etl', 'Extraindo-conversoes', 'scheduled__2024-03-04T09:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/exchange_rate_dag.py', '--cfg-path', '/tmp/tmpbok64scf']
[2024-03-05T21:04:00.173-0300] {standard_task_runner.py:88} INFO - Job 8: Subtask Extraindo-conversoes
[2024-03-05T21:04:00.232-0300] {task_command.py:423} INFO - Running <TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [running]> on host GabGalani.
[2024-03-05T21:04:00.266-0300] {abstractoperator.py:707} ERROR - Exception rendering Jinja template for task 'Extraindo-conversoes', field 'json'. Template: {'job_id': '292067935571330', 'notebook_params': {'data_execucao': '{{data_interval_end.strftime("%Y-%m-%d)}}'}}
Traceback (most recent call last):
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/models/abstractoperator.py", line 699, in _do_render_template_fields
    rendered_content = self.render_template(
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 186, in render_template
    return {k: self.render_template(v, context, jinja_env, oids) for k, v in value.items()}
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 186, in <dictcomp>
    return {k: self.render_template(v, context, jinja_env, oids) for k, v in value.items()}
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 186, in render_template
    return {k: self.render_template(v, context, jinja_env, oids) for k, v in value.items()}
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 186, in <dictcomp>
    return {k: self.render_template(v, context, jinja_env, oids) for k, v in value.items()}
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 173, in render_template
    template = jinja_env.from_string(value)
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/jinja2/environment.py", line 1105, in from_string
    return cls.from_code(self, self.compile(source), gs, None)
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/jinja2/environment.py", line 768, in compile
    self.handle_exception(source=source_hint)
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/jinja2/environment.py", line 936, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "<unknown>", line 1, in template
jinja2.exceptions.TemplateSyntaxError: unexpected char '"' at 29
[2024-03-05T21:04:00.267-0300] {taskinstance.py:2728} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2357, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2495, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context)
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2907, in render_templates
    original_task.render_template_fields(context)
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 1241, in render_template_fields
    self._do_render_template_fields(self, self.template_fields, context, jinja_env, set())
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/models/abstractoperator.py", line 699, in _do_render_template_fields
    rendered_content = self.render_template(
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 186, in render_template
    return {k: self.render_template(v, context, jinja_env, oids) for k, v in value.items()}
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 186, in <dictcomp>
    return {k: self.render_template(v, context, jinja_env, oids) for k, v in value.items()}
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 186, in render_template
    return {k: self.render_template(v, context, jinja_env, oids) for k, v in value.items()}
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 186, in <dictcomp>
    return {k: self.render_template(v, context, jinja_env, oids) for k, v in value.items()}
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/airflow/template/templater.py", line 173, in render_template
    template = jinja_env.from_string(value)
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/jinja2/environment.py", line 1105, in from_string
    return cls.from_code(self, self.compile(source), gs, None)
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/jinja2/environment.py", line 768, in compile
    self.handle_exception(source=source_hint)
  File "/home/gabriel/Documents/Airflow/venv/lib/python3.10/site-packages/jinja2/environment.py", line 936, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "<unknown>", line 1, in template
jinja2.exceptions.TemplateSyntaxError: unexpected char '"' at 29
[2024-03-05T21:04:00.271-0300] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=Executando-notebook-etl, task_id=Extraindo-conversoes, execution_date=20240304T090000, start_date=20240306T000400, end_date=20240306T000400
[2024-03-05T21:04:00.285-0300] {standard_task_runner.py:107} ERROR - Failed to execute job 8 for task Extraindo-conversoes (unexpected char '"' at 29; 28701)
[2024-03-05T21:04:00.305-0300] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-03-05T21:04:00.317-0300] {taskinstance.py:3309} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-05T21:08:56.130-0300] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [queued]>
[2024-03-05T21:08:56.138-0300] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [queued]>
[2024-03-05T21:08:56.139-0300] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-03-05T21:08:56.156-0300] {taskinstance.py:2214} INFO - Executing <Task(DatabricksRunNowOperator): Extraindo-conversoes> on 2024-03-04 09:00:00+00:00
[2024-03-05T21:08:56.160-0300] {standard_task_runner.py:60} INFO - Started process 31686 to run task
[2024-03-05T21:08:56.163-0300] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'Executando-notebook-etl', 'Extraindo-conversoes', 'scheduled__2024-03-04T09:00:00+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/exchange_rate_dag.py', '--cfg-path', '/tmp/tmprlxkasws']
[2024-03-05T21:08:56.165-0300] {standard_task_runner.py:88} INFO - Job 8: Subtask Extraindo-conversoes
[2024-03-05T21:08:56.203-0300] {task_command.py:423} INFO - Running <TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [running]> on host GabGalani.
[2024-03-05T21:08:56.271-0300] {taskinstance.py:2510} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='Executando-notebook-etl' AIRFLOW_CTX_TASK_ID='Extraindo-conversoes' AIRFLOW_CTX_EXECUTION_DATE='2024-03-04T09:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-03-04T09:00:00+00:00'
[2024-03-05T21:08:56.277-0300] {base.py:83} INFO - Using connection ID 'databricks_default' for task execution.
[2024-03-05T21:08:56.291-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T21:08:56.743-0300] {databricks.py:54} INFO - Run submitted with run_id: 1102206626500368
[2024-03-05T21:08:56.744-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T21:08:56.949-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T21:08:57.172-0300] {databricks.py:108} INFO - Extraindo-conversoes in run state: {'life_cycle_state': 'RUNNING', 'result_state': '', 'state_message': ''}
[2024-03-05T21:08:57.173-0300] {databricks.py:109} INFO - View run status, Spark UI, and logs at https://adb-2816171104137333.13.azuredatabricks.net/?o=2816171104137333#job/292067935571330/run/1102206626500368
[2024-03-05T21:08:57.173-0300] {databricks.py:110} INFO - Sleeping for 30 seconds.
[2024-03-05T21:09:27.203-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T21:09:27.448-0300] {databricks.py:65} INFO - Extraindo-conversoes completed successfully.
[2024-03-05T21:09:27.448-0300] {databricks.py:66} INFO - View run status, Spark UI, and logs at https://adb-2816171104137333.13.azuredatabricks.net/?o=2816171104137333#job/292067935571330/run/1102206626500368
[2024-03-05T21:09:27.452-0300] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=Executando-notebook-etl, task_id=Extraindo-conversoes, execution_date=20240304T090000, start_date=20240306T000856, end_date=20240306T000927
[2024-03-05T21:09:27.469-0300] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-03-05T21:09:27.477-0300] {taskinstance.py:3309} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-03-05T21:40:18.312-0300] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [queued]>
[2024-03-05T21:40:18.320-0300] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [queued]>
[2024-03-05T21:40:18.321-0300] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-03-05T21:40:18.338-0300] {taskinstance.py:2214} INFO - Executing <Task(DatabricksRunNowOperator): Extraindo-conversoes> on 2024-03-04 09:00:00+00:00
[2024-03-05T21:40:18.340-0300] {standard_task_runner.py:60} INFO - Started process 52607 to run task
[2024-03-05T21:40:18.344-0300] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'Executando-notebook-etl', 'Extraindo-conversoes', 'scheduled__2024-03-04T09:00:00+00:00', '--job-id', '49', '--raw', '--subdir', 'DAGS_FOLDER/exchange_rate_dag.py', '--cfg-path', '/tmp/tmpum29u32l']
[2024-03-05T21:40:18.349-0300] {standard_task_runner.py:88} INFO - Job 49: Subtask Extraindo-conversoes
[2024-03-05T21:40:18.389-0300] {task_command.py:423} INFO - Running <TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [running]> on host GabGalani.
[2024-03-05T21:40:18.468-0300] {taskinstance.py:2510} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='Executando-notebook-etl' AIRFLOW_CTX_TASK_ID='Extraindo-conversoes' AIRFLOW_CTX_EXECUTION_DATE='2024-03-04T09:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-03-04T09:00:00+00:00'
[2024-03-05T21:40:18.474-0300] {base.py:83} INFO - Using connection ID 'databricks_default' for task execution.
[2024-03-05T21:40:18.496-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T21:40:18.889-0300] {databricks.py:54} INFO - Run submitted with run_id: 72151116350329
[2024-03-05T21:40:18.889-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T21:40:19.078-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T21:40:19.288-0300] {databricks.py:108} INFO - Extraindo-conversoes in run state: {'life_cycle_state': 'RUNNING', 'result_state': '', 'state_message': ''}
[2024-03-05T21:40:19.288-0300] {databricks.py:109} INFO - View run status, Spark UI, and logs at https://adb-2816171104137333.13.azuredatabricks.net/?o=2816171104137333#job/292067935571330/run/72151116350329
[2024-03-05T21:40:19.289-0300] {databricks.py:110} INFO - Sleeping for 30 seconds.
[2024-03-05T21:40:49.319-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T21:40:49.564-0300] {databricks.py:65} INFO - Extraindo-conversoes completed successfully.
[2024-03-05T21:40:49.565-0300] {databricks.py:66} INFO - View run status, Spark UI, and logs at https://adb-2816171104137333.13.azuredatabricks.net/?o=2816171104137333#job/292067935571330/run/72151116350329
[2024-03-05T21:40:49.569-0300] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=Executando-notebook-etl, task_id=Extraindo-conversoes, execution_date=20240304T090000, start_date=20240306T004018, end_date=20240306T004049
[2024-03-05T21:40:49.601-0300] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-03-05T21:40:49.612-0300] {taskinstance.py:3309} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-05T22:10:06.586-0300] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [queued]>
[2024-03-05T22:10:06.601-0300] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [queued]>
[2024-03-05T22:10:06.602-0300] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-03-05T22:10:06.632-0300] {taskinstance.py:2214} INFO - Executing <Task(DatabricksRunNowOperator): Extraindo-conversoes> on 2024-03-04 09:00:00+00:00
[2024-03-05T22:10:06.636-0300] {standard_task_runner.py:60} INFO - Started process 60919 to run task
[2024-03-05T22:10:06.642-0300] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'Executando-notebook-etl', 'Extraindo-conversoes', 'scheduled__2024-03-04T09:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/exchange_rate_dag.py', '--cfg-path', '/tmp/tmpi2o9bcky']
[2024-03-05T22:10:06.643-0300] {standard_task_runner.py:88} INFO - Job 5: Subtask Extraindo-conversoes
[2024-03-05T22:10:06.695-0300] {task_command.py:423} INFO - Running <TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [running]> on host GabGalani.
[2024-03-05T22:10:06.782-0300] {taskinstance.py:2510} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='Executando-notebook-etl' AIRFLOW_CTX_TASK_ID='Extraindo-conversoes' AIRFLOW_CTX_EXECUTION_DATE='2024-03-04T09:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-03-04T09:00:00+00:00'
[2024-03-05T22:10:06.791-0300] {base.py:83} INFO - Using connection ID 'databricks_default' for task execution.
[2024-03-05T22:10:06.833-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T22:10:07.329-0300] {databricks.py:54} INFO - Run submitted with run_id: 233770985719845
[2024-03-05T22:10:07.329-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T22:10:07.525-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T22:10:07.801-0300] {databricks.py:108} INFO - Extraindo-conversoes in run state: {'life_cycle_state': 'RUNNING', 'result_state': '', 'state_message': ''}
[2024-03-05T22:10:07.802-0300] {databricks.py:109} INFO - View run status, Spark UI, and logs at https://adb-2816171104137333.13.azuredatabricks.net/?o=2816171104137333#job/292067935571330/run/233770985719845
[2024-03-05T22:10:07.802-0300] {databricks.py:110} INFO - Sleeping for 30 seconds.
[2024-03-05T22:10:37.833-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T22:10:38.120-0300] {databricks.py:65} INFO - Extraindo-conversoes completed successfully.
[2024-03-05T22:10:38.120-0300] {databricks.py:66} INFO - View run status, Spark UI, and logs at https://adb-2816171104137333.13.azuredatabricks.net/?o=2816171104137333#job/292067935571330/run/233770985719845
[2024-03-05T22:10:38.128-0300] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=Executando-notebook-etl, task_id=Extraindo-conversoes, execution_date=20240304T090000, start_date=20240306T011006, end_date=20240306T011038
[2024-03-05T22:10:38.179-0300] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-03-05T22:10:38.200-0300] {taskinstance.py:3309} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-03-05T22:25:00.269-0300] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [queued]>
[2024-03-05T22:25:00.284-0300] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [queued]>
[2024-03-05T22:25:00.284-0300] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-03-05T22:25:00.330-0300] {taskinstance.py:2214} INFO - Executing <Task(DatabricksRunNowOperator): Extraindo-conversoes> on 2024-03-04 09:00:00+00:00
[2024-03-05T22:25:00.336-0300] {standard_task_runner.py:60} INFO - Started process 66349 to run task
[2024-03-05T22:25:00.350-0300] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'Executando-notebook-etl', 'Extraindo-conversoes', 'scheduled__2024-03-04T09:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/exchange_rate_dag.py', '--cfg-path', '/tmp/tmpebrh4cj_']
[2024-03-05T22:25:00.361-0300] {standard_task_runner.py:88} INFO - Job 5: Subtask Extraindo-conversoes
[2024-03-05T22:25:00.551-0300] {task_command.py:423} INFO - Running <TaskInstance: Executando-notebook-etl.Extraindo-conversoes scheduled__2024-03-04T09:00:00+00:00 [running]> on host GabGalani.
[2024-03-05T22:25:00.663-0300] {taskinstance.py:2510} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='Executando-notebook-etl' AIRFLOW_CTX_TASK_ID='Extraindo-conversoes' AIRFLOW_CTX_EXECUTION_DATE='2024-03-04T09:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-03-04T09:00:00+00:00'
[2024-03-05T22:25:00.672-0300] {base.py:83} INFO - Using connection ID 'databricks_default' for task execution.
[2024-03-05T22:25:00.729-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T22:25:01.227-0300] {databricks.py:54} INFO - Run submitted with run_id: 424504188504526
[2024-03-05T22:25:01.228-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T22:25:01.419-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T22:25:01.644-0300] {databricks.py:108} INFO - Extraindo-conversoes in run state: {'life_cycle_state': 'RUNNING', 'result_state': '', 'state_message': ''}
[2024-03-05T22:25:01.645-0300] {databricks.py:109} INFO - View run status, Spark UI, and logs at https://adb-2816171104137333.13.azuredatabricks.net/?o=2816171104137333#job/292067935571330/run/424504188504526
[2024-03-05T22:25:01.646-0300] {databricks.py:110} INFO - Sleeping for 30 seconds.
[2024-03-05T22:25:31.677-0300] {databricks_base.py:500} INFO - Using token auth.
[2024-03-05T22:25:32.074-0300] {databricks.py:65} INFO - Extraindo-conversoes completed successfully.
[2024-03-05T22:25:32.075-0300] {databricks.py:66} INFO - View run status, Spark UI, and logs at https://adb-2816171104137333.13.azuredatabricks.net/?o=2816171104137333#job/292067935571330/run/424504188504526
[2024-03-05T22:25:32.084-0300] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=Executando-notebook-etl, task_id=Extraindo-conversoes, execution_date=20240304T090000, start_date=20240306T012500, end_date=20240306T012532
[2024-03-05T22:25:32.120-0300] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-03-05T22:25:32.152-0300] {taskinstance.py:3309} INFO - 1 downstream tasks scheduled from follow-on schedule check
